[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About vetiver",
    "section": "",
    "text": "Development of vetiver is sponsored by RStudio, PBC."
  },
  {
    "objectID": "about.html#is-vetiver-open-source",
    "href": "about.html#is-vetiver-open-source",
    "title": "About vetiver",
    "section": "Is vetiver open source?",
    "text": "Is vetiver open source?\nThe vetiver Python and R packages are released under the MIT license."
  },
  {
    "objectID": "about.html#what-are-different-ways-you-can-contribute",
    "href": "about.html#what-are-different-ways-you-can-contribute",
    "title": "About vetiver",
    "section": "What are different ways you can contribute?",
    "text": "What are different ways you can contribute?\n\nAnswer questions\nYou can help others use and learn vetiver by answering questions on the RStudio community site, Stack Overflow, and Twitter. Many people asking for help with vetiver don‚Äôt know what a reproducible example or ‚Äúreprex‚Äù is, or how to craft one. Acknowledging an individual‚Äôs problem, showing them how to build a reprex, and pointing them to helpful resources are all enormously beneficial, even if you don‚Äôt immediately solve their problem.\nRemember that while you might have seen a problem a hundred times before, it‚Äôs new to the person asking it. Be patient, polite, and empathetic.\n\n\nFile issues\nIf you‚Äôve found a bug, first create a minimal reproducible example. Spend some time working to make it as minimal as possible; the more time you spend doing this, the easier it is to fix the bug. When your reprex is ready, file it on the GitHub repo of the appropriate package, either Python or R.\nThe vetiver team often focuses on one package at a time to reduce context switching and be more efficient. We may not address each issue right away, but we will use the reproducible example you create to understand your problem when it is time to focus on that package.\n\n\nContribute documentation\nDocumentation is a high priority for vetiver, and pull requests to correct or improve documentation are welcome.\n\n\nContribute code\nIf you are a more experienced R or Python programmer, you may have the inclination, interest, and ability to contribute directly to package development. Before you submit a pull request to vetiver, always file an issue and confirm the vetiver team agrees with your idea and is happy with your basic proposal.\nWe use the tidyverse style guide for R and the PEP 8 style guide for Python. Using a style guide keeps your new code and documentation matching the existing style, and makes the review process much smoother."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MLOps with vetiver",
    "section": "",
    "text": "Vetiver, the oil of tranquility, is used as a stabilizing ingredient in perfumery to preserve more volatile fragrances.\n\nThe goal of vetiver is to provide fluent tooling to version, deploy, and monitor a trained model. Functions handle both recording and checking the model‚Äôs input data prototype, and predicting from a remote API endpoint.\n\n\n\n\n\n\n\n\n\n\n\nData scientists have effective tools that they ‚ù§Ô∏è to:\n\n\n\n\ncollect data\nprepare, manipulate, refine data\ntrain models\n\n\n\n\n\n\n\n\n\nThere is a lack üò© of effective tools to:\n\n\n\n\nversion and publish models\nput models into production\nmonitor model performance\n\n\n\nUse vetiver to version and deploy your trained models.\n\nRPython\n\n\n\nlibrary(vetiver)\ncars_lm <- lm(mpg ~ ., data = mtcars)\nvetiver_model(cars_lm, \"cars_linear\")\n\n\n‚îÄ‚îÄ cars_linear ‚îÄ <butchered_lm> model for deployment \nAn OLS linear regression model using 10 features\n\n\n\n\n\nfrom vetiver import VetiverModel\nfrom vetiver.data import mtcars\nfrom sklearn import linear_model\n\nmodel = linear_model.LinearRegression().fit(mtcars, mtcars[\"mpg\"])\nv = VetiverModel(model, model_name = \"cars_linear\", \n                 save_ptype = True, ptype_data = mtcars)\nv.description\n\n\"Scikit-learn <class 'sklearn.linear_model._base.LinearRegression'> model\""
  },
  {
    "objectID": "learn-more/deploy-with-docker.html",
    "href": "learn-more/deploy-with-docker.html",
    "title": "Deploy with Docker",
    "section": "",
    "text": "If you plan to bring vetiver to a public or private cloud outside of RStudio Connect, Docker containers are a highly portable solution. Using vetiver makes Dockerfile creation easy by generating the files you need from your trained models."
  },
  {
    "objectID": "learn-more/deploy-with-docker.html#import-data",
    "href": "learn-more/deploy-with-docker.html#import-data",
    "title": "Deploy with Docker",
    "section": "Import data",
    "text": "Import data\nFor this demo, we will use data from Tidy Tuesday to predict the number of YouTube likes a television commercial played during the Super Bowl will get, based on qualities such as if the ad included any animals, if the ad was funny, if the ad had any elements of danger, etc.\n\nPythonR\n\n\n\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(500)\n\nraw = pd.read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv')\ndf = pd.DataFrame(raw)\n\ndf = df[[\"like_count\", \"funny\", \"show_product_quickly\", \"patriotic\", \\\n    \"celebrity\", \"danger\", \"animals\"]].dropna()\n\ndf.head(3)\n\n   like_count  funny  show_product_quickly  ...  celebrity  danger  animals\n0      1233.0  False                 False  ...      False   False    False\n1       485.0   True                  True  ...       True    True    False\n2       129.0   True                 False  ...      False    True     True\n\n[3 rows x 7 columns]\n\n\n\n\n\nlibrary(tidyverse)\nsuperbowl_ads_raw <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-03-02/youtube.csv')\n\nsuperbowl_ads <-\n    superbowl_ads_raw %>%\n    select(funny:animals, like_count) %>%\n    na.omit()\n\nsuperbowl_ads\n\n# A tibble: 225 √ó 7\n   funny show_product_quickly patriotic celebrity danger animals like_count\n   <lgl> <lgl>                <lgl>     <lgl>     <lgl>  <lgl>        <dbl>\n 1 FALSE FALSE                FALSE     FALSE     FALSE  FALSE         1233\n 2 TRUE  TRUE                 FALSE     TRUE      TRUE   FALSE          485\n 3 TRUE  FALSE                FALSE     FALSE     TRUE   TRUE           129\n 4 FALSE TRUE                 FALSE     FALSE     FALSE  FALSE            2\n 5 TRUE  TRUE                 FALSE     FALSE     TRUE   TRUE            20\n 6 TRUE  TRUE                 FALSE     TRUE      TRUE   TRUE           115\n 7 TRUE  FALSE                FALSE     TRUE      FALSE  TRUE          1470\n 8 FALSE FALSE                FALSE     TRUE      FALSE  FALSE           78\n 9 TRUE  TRUE                 FALSE     TRUE      FALSE  TRUE           342\n10 FALSE TRUE                 TRUE      TRUE      TRUE   FALSE            7\n# ‚Ä¶ with 215 more rows"
  },
  {
    "objectID": "learn-more/deploy-with-docker.html#build-a-model",
    "href": "learn-more/deploy-with-docker.html#build-a-model",
    "title": "Deploy with Docker",
    "section": "Build a model",
    "text": "Build a model\nWith data in hand, the next step is feature engineering and model estimation. We put these two steps into a single function, such as a pipeline or workflow, and will deploy these pieces together. (Why are we doing this?)\n\nPythonR\n\n\n\nfrom sklearn import model_selection, preprocessing, pipeline\nfrom sklearn.ensemble import RandomForestRegressor\n\nX, y = df.iloc[:,1:],df['like_count']\nX_train, X_test, y_train, y_test = model_selection.train_test_split(\n    X, y,\n    test_size=0.2\n)\n\nle = preprocessing.OrdinalEncoder().fit(X)\nrf = RandomForestRegressor().fit(le.transform(X_train), y_train)\nrf_pipe = pipeline.Pipeline([('label_encoder',le), ('random_forest', rf)])\n\n\n\n\nlibrary(tidymodels)\n\nrf_spec <- rand_forest(mode = \"regression\")\nrf_form <- like_count ~ .\n\nrf_fit <-\n    workflow(rf_form, rf_spec) %>%\n    fit(superbowl_ads)"
  },
  {
    "objectID": "learn-more/deploy-with-docker.html#create-a-vetiver-model",
    "href": "learn-more/deploy-with-docker.html#create-a-vetiver-model",
    "title": "Deploy with Docker",
    "section": "Create a vetiver model",
    "text": "Create a vetiver model\nNext, let‚Äôs create a deployable model object with vetiver.\n\nPythonR\n\n\n\nimport vetiver\n\nv = vetiver.VetiverModel(\n    rf_pipe, \n    ptype_data=X_train, \n    model_name = \"superbowl_rf\"\n)\nv.description\n\n\"Scikit-learn <class 'sklearn.pipeline.Pipeline'> model\"\n\n\n\n\n\nlibrary(vetiver)\n\nv <- vetiver_model(rf_fit, \"superbowl_rf\")\nv\n\n\n‚îÄ‚îÄ superbowl_rf ‚îÄ <butchered_workflow> model for deployment \nA ranger regression modeling workflow using 6 features"
  },
  {
    "objectID": "learn-more/deploy-with-docker.html#version-your-model",
    "href": "learn-more/deploy-with-docker.html#version-your-model",
    "title": "Deploy with Docker",
    "section": "Version your model",
    "text": "Version your model\nWe pin our vetiver model to a board to version it. We will also use this board later to create artifacts to run our Dockerfile.\n\nPythonR\n\n\n\nimport pins\n\nboard = pins.board_rsconnect(\n    server_url=server_url, # load from an .env file\n    api_key=api_key, # load from an .env file \n    allow_pickle_read=True\n)\n\nvetiver.vetiver_pin_write(board, v)\n\n\n\n\nlibrary(pins)\nboard <- board_rsconnect() # authenticates via environment variables\nvetiver_pin_write(board, v)\n\n\n\n\nHere we are using board_rsconnect(), but you can use other boards such as board_s3(). Read more about how to store and version your vetiver model."
  },
  {
    "objectID": "learn-more/deploy-with-docker.html#create-api-and-docker-artifacts",
    "href": "learn-more/deploy-with-docker.html#create-api-and-docker-artifacts",
    "title": "Deploy with Docker",
    "section": "Create API and Docker artifacts",
    "text": "Create API and Docker artifacts\nNext, let‚Äôs create an app.py or plumber.R file. This file contains the information to create a vetiver REST API and will be running inside your Docker container.\nOnce you have this file, vetiver can help you write a Dockerfile.\n\nPythonR\n\n\n\nvetiver.write_app(\n    board, \n    \"isabel.zimmerman/superbowl_rf\", \n    version = \"20220901T144702Z-fd402\"\n)\nvetiver.write_docker()\n\n\n\n\n\n\n\nNote\n\n\n\nYou may need to edit the app.py file to load a .env file for authorization, if necessary.\nDocker also needs a requirements file. You can generate your own, or use vetiver.load_pkgs() to generate a file named vetiver_req.txt with the packages necessary for prediction.\n\n\n\n\n\nvetiver_write_plumber(board, \"julia.silge/superbowl_rf\")\nvetiver_write_docker(v, port=8080)\n\n\n\n\n\n\n\nNote\n\n\n\nWhen you run vetiver_write_docker(), you generate two files: the Dockerfile itself and the vetiver_renv.lock file to capture your model dependencies.\n\n\n\n\n\nYou have now created all the artifacts to run your Docker container!"
  },
  {
    "objectID": "learn-more/deploy-with-docker.html#build-and-run-your-dockerfile",
    "href": "learn-more/deploy-with-docker.html#build-and-run-your-dockerfile",
    "title": "Deploy with Docker",
    "section": "Build and run your Dockerfile",
    "text": "Build and run your Dockerfile\nIt is time to build and run your container. Building the Docker container can potentially take a while, because it installs all the packages needed to make a prediction with this model. Use the command line (not R or Python) to build your Docker container:\n\ndocker build -t superbowlads .\n\n\n\n\n\n\n\nTip\n\n\n\nIf you are on an ARM architecture locally and deploying an R model, use --platform linux/amd64 for RSPM‚Äôs fast installation of binaries.\n\n\nNow run! To authenticate to your board (to get the pinned vetiver model from, for example, RStudio Connect), pass in a file supplying environment variables.\n\ndocker run --env-file .env -p 8080:8080 superbowlads\n\n\n\n\n\n\n\nTip\n\n\n\nR users likely will store their environment variables in a file called .Renviron instead of .env.\n\n\nThe Docker container is now running locally! You can interact with it, such as by using a browser to visit http://0.0.0.0:8080/__docs__/"
  },
  {
    "objectID": "learn-more/deploy-with-docker.html#make-predictions-from-docker-container",
    "href": "learn-more/deploy-with-docker.html#make-predictions-from-docker-container",
    "title": "Deploy with Docker",
    "section": "Make predictions from Docker container",
    "text": "Make predictions from Docker container\nRunning a Docker container locally is a great way to test that you can make predictions from your endpoint as expected, using R or Python.\n\nPythonR\n\n\n\nendpoint = vetiver.vetiver_endpoint(\"http://0.0.0.0:8080/predict\")\nvetiver.predict(endpoint=endpoint, data=X_test)\n\n\n\n\nnew_ads <- superbowl_ads %>% \n    select(-like_count) %>% \n\nendpoint <- vetiver_endpoint(\"http://0.0.0.0:8080/predict\")\n\npredict(endpoint, new_ads)\n\n\n\n\nWhen you‚Äôre done, stop all Docker containers from the command line with:\n\ndocker stop $(docker ps -a -q)"
  },
  {
    "objectID": "learn-more/deploy-with-docker.html#what-if-i-dont-know-how-to-use-docker",
    "href": "learn-more/deploy-with-docker.html#what-if-i-dont-know-how-to-use-docker",
    "title": "Deploy with Docker",
    "section": "What if I don‚Äôt know how to use Docker?",
    "text": "What if I don‚Äôt know how to use Docker?\nDocker is a great tool for data scientists, so learning the basics is a good idea. These resources can help you get started:\n\nEnough Docker to be Dangerous\nDocker for the UseR\nDocker tutorial for reproducible research\nPython Docker\nTen simple rules for writing Dockerfiles for reproducible data science\nDocker and Python: making them play nicely and securely for Data Science and ML\nDocker info from RStudio Solutions Engineering"
  },
  {
    "objectID": "learn-more/model-card.html",
    "href": "learn-more/model-card.html",
    "title": "Model cards for transparent, responsible reporting",
    "section": "",
    "text": "Good documentation helps us make sense of software, know when and how to use it, and understand its purpose. The same can be true of documentation or reporting for a deployed model, but it can be hard to know where to start. The paper ‚ÄúModel Cards for Model Reporting‚Äù (Mitchell et al.¬†2019) provides a suggested framework for organizing and presenting the essential facts about a deployed machine learning model. The vetiver package provides an R Markdown template for creating a ‚ÄúModel Card‚Äù for a published vetiver model. The template automates extracting some information from the model object, and provides structure for the model developer where automation is not possible.\nModel developers see a nudge to create a model card when they publish a model; we recommend that you create a model card when you deploy a model for the first time and refresh that model card as needed when new versions are deployed.\n\nRPython\n\n\n\nlibrary(vetiver)\nlibrary(pins)\nmodel_board <- board_temp()\n\ncars_lm <- lm(mpg ~ ., data = mtcars)\nv <- vetiver_model(cars_lm, \"cars_linear\")\nvetiver_pin_write(model_board, v)\n\nCreating new version '20220919T211923Z-2bb55'\nWriting to pin 'cars_linear'\n\nCreate a Model Card for your published model\n‚Ä¢ Model Cards provide a framework for transparent, responsible reporting\n‚Ä¢ Use the vetiver `.Rmd` template as a place to start\n\n\n(Learn more about silencing messages like this if desired.)\n\n\n\nimport vetiver\nimport pins\nfrom vetiver.data import mtcars\nfrom sklearn.linear_model import LinearRegression\n\nmodel_board = pins.board_temp(allow_pickle_read=True)\n\nmodel = LinearRegression().fit(mtcars, mtcars[\"mpg\"])\nv = vetiver.VetiverModel(model, model_name = \"cars_linear\", \n                 save_ptype = True, ptype_data = mtcars)\n\nvetiver.vetiver_pin_write(model_board, v)\n\nModel Cards provide a framework for transparent, responsible reporting. \n Use the vetiver `.qmd` Quarto template as a place to start, \n with vetiver.model_card()\nWriting pin:\nName: 'cars_linear'\nVersion: 20220919T211928Z-64c37\n\n\nTo silence this message,\nfrom vetiver.utils import modelcard_options\n\nmodelcard_options.quiet = True"
  },
  {
    "objectID": "learn-more/model-card.html#accessing-the-template",
    "href": "learn-more/model-card.html#accessing-the-template",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Accessing the template",
    "text": "Accessing the template\n\nRPython\n\n\nTo use the vetiver model card template from RStudio, access through File -> New File -> R Markdown. This will open the dialog box where you can select from one of the available templates:\n\n\n\n\n\nIf you are not using RStudio, you‚Äôll also need to install Pandoc. Then, use the rmarkdown::draft() function to create the model card:\nrmarkdown::draft(\n    \"my_model_card.Rmd\", \n    template = \"vetiver_model_card\", \n    package = \"vetiver\"\n)\n\n\nTo use a model card template with Python, you will need to have Quarto installed. Then, use the vetiver.model_card() function to generate the template.\nvetiver.model_card(path = \".\")"
  },
  {
    "objectID": "learn-more/model-card.html#model-card-outline",
    "href": "learn-more/model-card.html#model-card-outline",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Model card outline",
    "text": "Model card outline\nThere are several sections in the model card framework used here.\n\nModel details: Some details about your model can be determined from the model object itself, but some (like who developed the model and license or citation information) need to be provided by you.\nIntended use: Outline the intended use and users of the model, and perhaps also what types of use would be out of scope.\nImportant aspects/factors: What are the demographic, environmental, technical, or other aspects that are relevant to the context of the model?\nPerformance metrics: Communicate which metrics are being used to evaluate the model, and why these are a good fit for the model‚Äôs context and domain.\nTraining data & evaluation data: Some specific dataset was used to train the model, so be sure to share basic details about its characteristics. (Some information about the training data can be extracted from the model object itself.) Some (probably different) specific dataset is used to evaluate the model in the context of the model card, so also explain what the evaluation data is like.\nQuantitative analyses: Provide the results of evaluating the model using your chosen metrics and the evaluation data. Be sure to present both overall results (for the dataset as a whole) and disaggregated results, especially with any aspects (demographic, environmental, or other) in mind that have been identified as important for this model. You can use both tables and visualization to present these quantitative analyses.\nEthical considerations: Share ethical considerations and any possible solutions considered. Some specific aspects to note are any sensitive data used, impact on human life, possible risks and harms, and important use cases.\nCaveats & recommendations: As the model developer, you likely have the most domain knowledge of what the model can and cannot do. This section is a good place to share any additional thoughts, perhaps including how your own identity may or may not come into play in the model‚Äôs context."
  },
  {
    "objectID": "learn-more/model-card.html#cant-i-just-delete-the-section-on-ethical-considerations",
    "href": "learn-more/model-card.html#cant-i-just-delete-the-section-on-ethical-considerations",
    "title": "Model cards for transparent, responsible reporting",
    "section": "Can‚Äôt I just delete the section on ethical considerations?",
    "text": "Can‚Äôt I just delete the section on ethical considerations?\nIt‚Äôs possible that a given machine learning model may not have obvious caveats, ethical challenges, or demographic aspects, or that they are largely unknown. However, we strongly advise that instead of deleting any such section because you have incomplete or imprecise information, you note your own process and considerations. Also, consider the possibility of gathering feedback from those impacted by the machine learning system, especially those with marginalized identities.\nThe process of documenting the extent and limits of a machine learning system is part of transparent, responsible reporting. A model card framework such as this is a helpful tool and some parts of a model card can be automated, but ultimately the extent of its value depends on you. From Mitchell et al.¬†(2019):\n\nTherefore the usefulness and accuracy of a model card relies on the integrity of the creator(s) of the card itself."
  },
  {
    "objectID": "learn-more/parity-checklist.html",
    "href": "learn-more/parity-checklist.html",
    "title": "Function parity for R and Python",
    "section": "",
    "text": "Function\nR\nPython\n\n\n\n\nCreate a vetiver object for deployment of a trained model\nvetiver_model() new_vetiver_model()\nVetiverModel()\n\n\nRead and write a trained model to a board of models\nvetiver_pin_write() vetiver_pin_read()\nvetiver_pin_write() VetiverModel.from_pin()\n\n\nCreate an API to predict with a deployable vetiver_model() object\nvetiver_api() vetiver_pr_post() vetiver_pr_docs()\nVetiverAPI() VetiverAPI.vetiver_post()\n\n\nWrite a deployable API file for a vetiver model\nvetiver_write_plumber()\nwrite_app()\n\n\nDeploy a vetiver model API to RStudio Connect\nvetiver_deploy_rsconnect()\ndeploy_rsconnect()\n\n\nCreate a model API endpoint object for prediction\nvetiver_endpoint()\nvetiver_endpoint()\n\n\nPost new data to a deployed model API endpoint and return predictions\npredict()\npredict()\n\n\nFully attach or load packages for making model predictions\nattach_pkgs() load_pkgs()\nload_pkgs()\n\n\nModel handler functions for API endpoint\nhandler_startup() handler_predict()\nVetiverHandler.handler_predict()\n\n\nIdentify data types for each column in an input data prototype\nmap_request_body()\n\n\n\nModel constructor methods\nvetiver_create_description() vetiver_prepare_model()\nVetiverHandler.describe()\n\n\nMetadata constructors for vetiver model object\nvetiver_meta() vetiver_create_meta()\nVetiverHandler.create_meta() vetiver_create_meta()\n\n\nCreate a vetiver input data prototype\nvetiver_ptype() vetiver_create_ptype()\nvetiver_create_ptype()\n\n\nConvert new data at prediction time using input data prototype\nvetiver_type_convert()"
  },
  {
    "objectID": "get-started/index.html",
    "href": "get-started/index.html",
    "title": "Getting Started",
    "section": "",
    "text": "The vetiver framework for MLOps tasks is built for data science teams using R and/or Python, with a native, fluent experience for both. It is built to be extensible, with methods that can support many kinds of models."
  },
  {
    "objectID": "get-started/index.html#installation",
    "href": "get-started/index.html#installation",
    "title": "Getting Started",
    "section": "Installation",
    "text": "Installation\n\nRPython\n\n\nYou can use vetiver with:\n\na tidymodels workflow\ncaret\nmlr3\nXGBoost\nranger\nlm() and glm()\n\nYou can install the released version of vetiver from CRAN:\n\ninstall.packages(\"vetiver\")\n\nAnd the development version from GitHub with:\n\n# install.packages(\"devtools\")\ndevtools::install_github(\"tidymodels/vetiver-r\")\n\n\n\nYou can use vetiver with:\n\nscikit-learn\nPyTorch\nxgboost\nstatsmodels\n\nYou can install the released version of vetiver from PyPI:\n\npython -m pip install vetiver\n\nAnd the development version from GitHub with:\n\npython -m pip install git+https://github.com/rstudio/vetiver-python"
  },
  {
    "objectID": "get-started/index.html#train-a-model",
    "href": "get-started/index.html#train-a-model",
    "title": "Getting Started",
    "section": "Train a model",
    "text": "Train a model\nFor this example, let‚Äôs work with data on fuel efficiency for cars to predict miles per gallon.\n\nRPython\n\n\nLet‚Äôs consider one kind of model supported by vetiver, a tidymodels workflow that encompasses both feature engineering and model estimation.\n\nlibrary(tidymodels)\n\ncar_mod <-\n    workflow(mpg ~ ., linear_reg()) %>%\n    fit(mtcars)\n\n\n\nLet‚Äôs consider one kind of model supported by vetiver, a scikit-learn linear model.\n\nfrom vetiver.data import mtcars\nfrom sklearn import linear_model\n\ncar_mod = linear_model.LinearRegression().fit(mtcars.drop(columns=\"mpg\"), mtcars[\"mpg\"])\n\n\n\n\nThis car_mod object is a fitted model, with model parameters estimated using mtcars."
  },
  {
    "objectID": "get-started/index.html#create-a-vetiver-model",
    "href": "get-started/index.html#create-a-vetiver-model",
    "title": "Getting Started",
    "section": "Create a vetiver model",
    "text": "Create a vetiver model\nWe can create a vetiver_model() in R or VetiverModel() in Python from the trained model; a vetiver model object collects the information needed to store, version, and deploy a trained model.\n\nRPython\n\n\n\nlibrary(vetiver)\nv <- vetiver_model(car_mod, \"cars_mpg\")\nv\n\n\n‚îÄ‚îÄ cars_mpg ‚îÄ <butchered_workflow> model for deployment \nA lm regression modeling workflow using 10 features\n\n\n\n\n\nfrom vetiver import VetiverModel\nv = VetiverModel(car_mod, model_name = \"cars_mpg\", \n                 save_ptype = True, ptype_data = mtcars)\nv.description\n\n\"Scikit-learn <class 'sklearn.linear_model._base.LinearRegression'> model\"\n\n\n\n\n\nThink of this vetiver model as a deployable model object."
  },
  {
    "objectID": "get-started/version.html",
    "href": "get-started/version.html",
    "title": "Version",
    "section": "",
    "text": "RPython\n\n\n\n\nShow the code from previous steps\nlibrary(tidymodels)\nlibrary(vetiver)\n\ncar_mod <-\n    workflow(mpg ~ ., linear_reg()) %>%\n    fit(mtcars)\nv <- vetiver_model(car_mod, \"cars_mpg\")\n\n\n\n\n\n\nShow the code from previous steps\nfrom vetiver.data import mtcars\nfrom vetiver import VetiverModel\nfrom sklearn import linear_model\n\ncar_mod = linear_model.LinearRegression().fit(mtcars.drop(columns=\"mpg\"), mtcars[\"mpg\"])\n\nv = VetiverModel(car_mod, model_name = \"cars_mpg\", \n                 save_ptype = True, ptype_data = mtcars)"
  },
  {
    "objectID": "get-started/version.html#store-and-version-your-model",
    "href": "get-started/version.html#store-and-version-your-model",
    "title": "Version",
    "section": "Store and version your model",
    "text": "Store and version your model\nYou can store and version your model by choosing a pins ‚Äúboard‚Äù for it. Your board for model pins can be set up to use a local folder, RStudio Connect, Amazon S3, and more. When we write the vetiver model to our board, the binary model object is stored on our board together with necessary metadata, like the packages needed to make a prediction and the model‚Äôs input data prototype for checking new data at prediction time.\n\n\n\n\n\n\nNote\n\n\n\nWe‚Äôll use a temporary board that will be automatically deleted for this demo, but for your real work, you will want to choose the best board for your particular infrastructure.\n\n\n\nRPython\n\n\nMost pins boards have versioning turned on by default, but we can turn it on explicitly for our temporary demo board.\n\nlibrary(pins)\nmodel_board <- board_temp(versioned = TRUE)\nmodel_board %>% vetiver_pin_write(v)\n\n\n\n\nfrom pins import board_temp\nfrom vetiver import vetiver_pin_write\nmodel_board = board_temp(versioned = True, allow_pickle_read = True)\nvetiver_pin_write(model_board, v)\n\n\n\n\nLet‚Äôs train a new kind of model for mtcars, a decision tree instead of our original linear model.\n\n\n\n\nRPython\n\n\n\ncar_mod <-\n    workflow(mpg ~ ., decision_tree(mode = \"regression\")) %>%\n    fit(mtcars)\n\nv <- vetiver_model(car_mod, \"cars_mpg\")\n\nmodel_board %>% vetiver_pin_write(v)\n\n\n\n\nfrom sklearn import tree\ncar_mod = tree.DecisionTreeRegressor().fit(mtcars.drop(columns=\"mpg\"), mtcars[\"mpg\"])\n\nv = VetiverModel(car_mod, model_name = \"cars_mpg\", \n                 save_ptype = True, ptype_data = mtcars)\nvetiver_pin_write(model_board, v)\n\n\n\n\nBoth versions are stored, and we have access to both.\n\nRPython\n\n\n\nmodel_board %>% pin_versions(\"cars_mpg\")\n\n# A tibble: 2 √ó 3\n  version                created             hash \n  <chr>                  <dttm>              <chr>\n1 20220919T211948Z-1501e 2022-09-19 21:19:00 1501e\n2 20220919T211951Z-dc266 2022-09-19 21:19:00 dc266\n\n\n\n\n\nmodel_board.pin_versions(\"cars_mpg\")\n\n              created   hash                 version\n0 2022-09-19 21:19:50  a82a6  20220919T211950Z-a82a6\n1 2022-09-19 21:19:54  b59bd  20220919T211954Z-b59bd\n\n\n\n\n\nThe primary purpose of pins is to make it easy to share data artifacts, so depending on the board you choose, your pinned vetiver model can be shareable with your collaborators."
  },
  {
    "objectID": "get-started/deploy.html",
    "href": "get-started/deploy.html",
    "title": "Deploy",
    "section": "",
    "text": "RPython\n\n\n\n\nShow the code from previous steps\nlibrary(tidymodels)\nlibrary(vetiver)\nlibrary(pins)\n\ncar_mod <-\n    workflow(mpg ~ ., decision_tree(mode = \"regression\")) %>%\n    fit(mtcars)\nv <- vetiver_model(car_mod, \"cars_mpg\")\nmodel_board <- board_folder(\"pins-r\", versioned = TRUE)\nmodel_board %>% vetiver_pin_write(v)\n\n\n\n\n\n\nShow the code from previous steps\nfrom vetiver.data import mtcars\nfrom vetiver import VetiverModel, vetiver_pin_write\nfrom sklearn import tree\nfrom pins import board_folder\n\ncar_mod = tree.DecisionTreeRegressor().fit(mtcars.drop(columns=\"mpg\"), mtcars[\"mpg\"])\n\nv = VetiverModel(car_mod, model_name = \"cars_mpg\", \n                 save_ptype = True, ptype_data = mtcars.drop(columns=\"mpg\"))\n\nmodel_board = board_folder(\"pins-py\", allow_pickle_read=True)\nvetiver_pin_write(model_board, v)"
  },
  {
    "objectID": "get-started/deploy.html#create-a-rest-api-for-deployment",
    "href": "get-started/deploy.html#create-a-rest-api-for-deployment",
    "title": "Deploy",
    "section": "Create a REST API for deployment",
    "text": "Create a REST API for deployment\nYou can deploy your model by creating a special Plumber router in R or a FastAPI router in Python, and adding a POST endpoint for making predictions.\n\nRPython\n\n\n\nlibrary(plumber)\npr() %>%\n  vetiver_api(v)\n\n# Plumber router with 2 endpoints, 4 filters, and 1 sub-router.\n# Use `pr_run()` on this object to start the API.\n‚îú‚îÄ‚îÄ[queryString]\n‚îú‚îÄ‚îÄ[body]\n‚îú‚îÄ‚îÄ[cookieParser]\n‚îú‚îÄ‚îÄ[sharedSecret]\n‚îú‚îÄ‚îÄ/logo\n‚îÇ  ‚îÇ # Plumber static router serving from directory: /home/runner/work/_temp/Library/vetiver\n‚îú‚îÄ‚îÄ/ping (GET)\n‚îî‚îÄ‚îÄ/predict (POST)\n\n\nTo start a server using this object, pipe (%>%) to pr_run(port = 8080) or your port of choice.\n\n\n\nfrom vetiver import VetiverAPI\napp = VetiverAPI(v, check_ptype = True)\n\nTo start a server using this object, use app.run(port = 8080) or your port of choice.\n\n\n\nYou can interact with your vetiver API via automatically generated, detailed visual documentation.\n\n\n\n\n\n\n\n\n\n\n\n\nFastAPI and Plumber APIs such as these can be hosted in a variety of ways. You can create a ready-to-go file for deployment that is especially suited for RStudio Connect.\n\nRPython\n\n\n\nvetiver_write_plumber(model_board, \"cars_mpg\")\n\n\n\n# Generated by the vetiver package; edit with care\n\nlibrary(pins)\nlibrary(plumber)\nlibrary(rapidoc)\nlibrary(vetiver)\nb <- board_folder(path = \"pins-r\")\nv <- vetiver_pin_read(b, \"cars_mpg\", version = \"20220919T212001Z-e3308\")\n\n#* @plumber\nfunction(pr) {\n    pr %>% vetiver_api(v)\n}\n\n\nFor RStudio Connect, you can streamline this deployment process even more by using vetiver_deploy_rsconnect(model_board, \"cars_mpg\").\n\n\n\napp_file = vetiver.write_app(model_board, \"cars_mpg\")\n\n\n\nfrom vetiver import VetiverModel\nimport vetiver\nimport pins\n\n\nb = pins.board_folder('pins-py', allow_pickle_read=True)\nv = VetiverModel.from_pin(b, 'cars_mpg', version = '20220919T212005Z-5f6e4')\n\nvetiver_api = vetiver.VetiverAPI(v)\napi = vetiver_api.app\n\n\n\n\n\nIn a real-world situation, you would see something like board_rsconnect() or board_s3() here instead of our temporary demo board.\n\n\n\n\n\n\nImportant\n\n\n\nNotice that the deployment is strongly linked to a specific version of the pinned model; if you pin another version of the model after you deploy your model, your deployed model will not be affected."
  },
  {
    "objectID": "get-started/deploy.html#generate-a-dockerfile",
    "href": "get-started/deploy.html#generate-a-dockerfile",
    "title": "Deploy",
    "section": "Generate a Dockerfile",
    "text": "Generate a Dockerfile\nFor deploying a vetiver API to infrastructure other than RStudio Connect, such as Google Cloud Run, AWS, or Azure, you likely will want to build a Docker container.\n\n\n\n\n\n\nNote\n\n\n\nYou can use any pins board with Docker, like board_folder() or board_rsconnect(), as long as your Docker container can authenticate to your pins board.\n\n\n\nRPython\n\n\n\nvetiver_write_docker(v)\n\n\n\n# Generated by the vetiver package; edit with care\n\nFROM rocker/r-ver:4.2.1\nENV RENV_CONFIG_REPOS_OVERRIDE https://packagemanager.rstudio.com/cran/latest\n\nRUN apt-get update -qq && apt-get install -y --no-install-recommends \\\n  libcurl4-openssl-dev \\\n  libicu-dev \\\n  libsodium-dev \\\n  libssl-dev \\\n  make\n\nCOPY vetiver_renv.lock renv.lock\nRUN Rscript -e \"install.packages('renv')\"\nRUN Rscript -e \"renv::restore()\"\nCOPY plumber.R /opt/ml/plumber.R\nEXPOSE 8000\nENTRYPOINT [\"R\", \"-e\", \"pr <- plumber::plumb('/opt/ml/plumber.R'); pr$run(host = '0.0.0.0', port = 8000)\"]\n\n\nWhen you run vetiver_write_docker(), you generate two files: the Dockerfile itself and the vetiver_renv.lock file to capture your model dependencies.\n\n\n\nvetiver.write_docker(app_file)\n\n\n\n# # Generated by the vetiver package; edit with care\n# start with python base image\nFROM python:3.8\n\n# create directory in container for vetiver files\nWORKDIR /vetiver\n\n# copy  and install requirements\nCOPY vetiver_requirements.txt /vetiver/requirements.txt\n\n#\nRUN pip install --no-cache-dir --upgrade -r /vetiver/requirements.txt\n\n# copy app file\nCOPY ./app.py /vetiver/app\n\n# expose port\nEXPOSE 8080\n\n# run vetiver API\nCMD [\"uvicorn\", \"app.app:api\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n\n\nTo build the Docker image, you need two files: the Dockerfile itself generated via vetiver_write_docker() and a requirements.txt file to capture your model dependencies. If you don‚Äôt already have a requirements file for your project, vetiver.load_pkgs() will generate one for you, with the name vetiver_requirements.txt.\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nWhen you build such a Docker container with docker build, all the packages needed to make a prediction with your model are installed into the container.\nWhen you run the Docker container, you can pass in environment variables (for authentication to your pins board, for example) with docker run --env-file .Renviron."
  },
  {
    "objectID": "get-started/deploy.html#predict-from-your-model-endpoint",
    "href": "get-started/deploy.html#predict-from-your-model-endpoint",
    "title": "Deploy",
    "section": "Predict from your model endpoint",
    "text": "Predict from your model endpoint\nA model deployed via vetiver can be treated as a special vetiver_endpoint() object.\n\nRPython\n\n\n\nendpoint <- vetiver_endpoint(\"http://127.0.0.1:8080/predict\")\nendpoint\n\n\n‚îÄ‚îÄ A model API endpoint for prediction: \nhttp://127.0.0.1:8080/predict\n\n\n\n\n\nfrom vetiver.server import predict, vetiver_endpoint\nendpoint = vetiver_endpoint(\"http://127.0.0.1:8080/predict\")\nendpoint\n\n'http://127.0.0.1:8080/predict'\n\n\n\n\n\nIf such a deployed model endpoint is running via one process (either remotely on a server or locally, perhaps via a background job in the RStudio IDE), you can make predictions with that deployed model and new data in another, separate process1.\n\nRPython\n\n\n\nnew_car <- tibble(cyl = 4,  disp = 200, \n                  hp = 100, drat = 3,\n                  wt = 3,   qsec = 17, \n                  vs = 0,   am = 1,\n                  gear = 4, carb = 2)\npredict(endpoint, new_car)\n\n# A tibble: 11 √ó 1\n   .pred\n   <chr>      \n 1 22.3       \n\n\n\nimport pandas as pd\nnew_car_dict = {\"cyl\": [4], \"disp\": [200], \n                 \"hp\": [100], \"drat\": [3],\n                 \"wt\": [3], \"qsec\": [17], \n                 \"vs\": [0], \"am\": [1],\n                 \"gear\": [4], \"carb\": [2]}\nnew_car = pd.DataFrame(new_car_dict)\npredict(endpoint, new_car)\n\n  prediction\n0       21.0\n\n\n\nBeing able to predict with a vetiver model endpoint takes advantage of the model‚Äôs input data prototype and other metadata that is stored with the model."
  },
  {
    "objectID": "get-started/monitor.html",
    "href": "get-started/monitor.html",
    "title": "Monitor",
    "section": "",
    "text": "Once a model is deployed, it is important to monitor its statistical performance. Machine learning can break quietly; a model can continue returning predictions without error, even if it is performing poorly. Without monitoring for degradation, this silent failure can continue undiagnosed. The vetiver framework offers functions to fluently compute, store, and plot model metrics. These functions are particularly suited to monitoring your model using multiple performance metrics over time.\nWhen a model is deployed, new data comes in over time, even if time is not a feature for prediction. Even if your model does not explicitly use any dates, a measure of time like a date can affect your model performance."
  },
  {
    "objectID": "get-started/monitor.html#build-a-model",
    "href": "get-started/monitor.html#build-a-model",
    "title": "Monitor",
    "section": "Build a model",
    "text": "Build a model\n\nRPython\n\n\n\n\nShow the code from previous steps\nlibrary(pins)\nlibrary(vetiver)\nlibrary(workflows)\n\nmodel_board <- board_folder(path = \"pins-r\")\nv <- vetiver_pin_read(model_board, \"cars_mpg\")\n\n\n\n\n\n\nShow the code from previous steps\nfrom vetiver import VetiverModel\nfrom pins import board_folder\n\nmodel_board = board_folder(\"pins-py\", allow_pickle_read=True)\nv = VetiverModel.from_pin(model_board, \"cars_mpg\")"
  },
  {
    "objectID": "get-started/monitor.html#compute-metrics",
    "href": "get-started/monitor.html#compute-metrics",
    "title": "Monitor",
    "section": "Compute metrics",
    "text": "Compute metrics\nLet‚Äôs say we collect new data on fuel efficiency in cars and we want to monitor the performance of our model over time. We can compute multiple metrics at once over a certain time aggregation.\n\nRPython\n\n\n\nlibrary(vetiver)\nlibrary(tidyverse)\ncars <- read_csv(\"https://vetiver.rstudio.com/get-started/new-cars.csv\")\noriginal_cars <- slice(cars, 1:14)\n\noriginal_metrics <-\n    augment(v, new_data = original_cars) %>%\n    vetiver_compute_metrics(date_obs, \"week\", mpg, .pred)\n\noriginal_metrics\n\n# A tibble: 6 √ó 5\n  .index        .n .metric .estimator .estimate\n  <date>     <int> <chr>   <chr>          <dbl>\n1 2022-03-24     7 rmse    standard       4.03 \n2 2022-03-24     7 rsq     standard       0.544\n3 2022-03-24     7 mae     standard       3.05 \n4 2022-03-31     7 rmse    standard       5.69 \n5 2022-03-31     7 rsq     standard       0.651\n6 2022-03-31     7 mae     standard       3.95 \n\n\n\n\n\nimport vetiver\n\nimport pandas as pd\nfrom sklearn import metrics\nfrom datetime import timedelta\n\ncars = pd.read_csv(\"https://vetiver.rstudio.com/get-started/new-cars.csv\")\noriginal_cars = cars.iloc[:14, :].copy()\noriginal_cars[\"preds\"] = v.model.predict(\n    original_cars.drop(columns=[\"date_obs\", \"mpg\"])\n)\n\nmetric_set = [metrics.mean_absolute_error, \n  metrics.mean_squared_error, \n  metrics.r2_score]\n  \ntd = timedelta(weeks = 1)\n\noriginal_metrics = vetiver.compute_metrics(\n    data = original_cars, \n    date_var = \"date_obs\", \n    period = td, \n    metric_set = metric_set, \n    truth = \"mpg\", \n    estimate = \"preds\"\n)\n\noriginal_metrics\n\n       index  n               metric   estimate\n0 2022-03-24  7  mean_absolute_error   3.692857\n1 2022-03-24  7   mean_squared_error  15.593793\n2 2022-03-24  7             r2_score   0.185795\n3 2022-03-31  7  mean_absolute_error   1.474946\n4 2022-03-31  7   mean_squared_error   4.513431\n5 2022-03-31  7             r2_score   0.866304"
  },
  {
    "objectID": "get-started/monitor.html#pin-metrics",
    "href": "get-started/monitor.html#pin-metrics",
    "title": "Monitor",
    "section": "Pin metrics",
    "text": "Pin metrics\nThe first time you pin monitoring metrics, you can write to a board as normal.\n\nRPython\n\n\n\nmodel_board %>% pin_write(original_metrics, \"tree_metrics\")\n\n\n\n\nmodel_board.pin_write(original_metrics, \"tree_metrics\", type = \"csv\")\n\n\n\n\nHowever, when adding new metrics measurements to your pin as you continue to gather new data and monitor, you may have dates that overlap with those already in the pin, depending on your monitoring strategy. You can choose how to handle overlapping dates with the overwrite argument.\n\nRPython\n\n\n\n# dates overlap with existing metrics:\nnew_cars <- slice(cars, -1:-7)\nnew_metrics <-\n    augment(v, new_data = new_cars) %>%\n    vetiver_compute_metrics(date_obs, \"week\", mpg, .pred)\n\nmodel_board %>%\n    vetiver_pin_metrics(new_metrics, \"tree_metrics\", overwrite = TRUE)\n\n\n\n\n# dates overlap with existing metrics:\nnew_cars = cars.iloc[7:, :].copy()\nnew_cars[\"preds\"] = v.model.predict(\n    new_cars.drop(columns=[\"date_obs\", \"mpg\"])\n)\n\nnew_metrics = vetiver.compute_metrics(\n    data = new_cars, \n    date_var = \"date_obs\", \n    period = td, \n    metric_set = metric_set, \n    truth = \"mpg\", \n    estimate = \"preds\"\n)\n                    \nvetiver.pin_metrics(\n    model_board, \n    new_metrics, \n    \"tree_metrics\", \n    overwrite = True\n)"
  },
  {
    "objectID": "get-started/monitor.html#plot-metrics",
    "href": "get-started/monitor.html#plot-metrics",
    "title": "Monitor",
    "section": "Plot metrics",
    "text": "Plot metrics\nYou can visualize your set of computed metrics and your model‚Äôs performance1.\n\nRPython\n\n\n\nlibrary(ggplot2)\nmonitoring_metrics <- model_board %>% pin_read(\"tree_metrics\")\nvetiver_plot_metrics(monitoring_metrics) +\n    scale_size(range = c(2, 4))\n\n\n\n\n\n\n\n\n\n\n\nmonitoring_metrics = model_board.pin_read(\"tree_metrics\")\np = vetiver.plot_metrics(df_metrics = monitoring_metrics)\np.update_yaxes(matches=None)\np.show()"
  },
  {
    "objectID": "get-started/monitor.html#build-a-dashboard",
    "href": "get-started/monitor.html#build-a-dashboard",
    "title": "Monitor",
    "section": "Build a dashboard",
    "text": "Build a dashboard\nThe vetiver package provides an R Markdown template for creating a monitoring dashboard. The template automates extracting some information from your metrics, and provides a way to extend the dashboard for a custom monitoring implementation."
  }
]